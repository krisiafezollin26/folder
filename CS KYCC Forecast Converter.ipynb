{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc2dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bens_forecasting_utils as fc\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34db75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    \n",
    "    # cs kycc forecast converter:\n",
    "    sheet_id                    = '1a_v0g2y5DvqLDbXXJC0m7i3PjF2AseC3lqoRwlGxg1o',\n",
    "    raw_marketing_forecast      = 'raw_marketing_forecast!A1:S',\n",
    "    tnc_to_lang                 = 'Tnc_to_Lang!A1:F',\n",
    "    intra_month                 = 'kycc_by_lang_intra-month_seasonality!A1:D',\n",
    "    intra_week                  = 'kycc_by_lang_intra-week_seasonality!A1:E' ,\n",
    "    cohorts                     = 'cohorts!A1:B',\n",
    "    kycc_volume                 = 'kycc_volume!A1:F',\n",
    "    holiday_sheet_id            = '199I1PNPhdbOW_ytQK_zLoby_J0Wk1XHA1spXNqEbMuE',\n",
    "    holiday_range               = 'holidays!A1:F'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a655e02",
   "metadata": {},
   "source": [
    "### generating df_cohort\n",
    "\n",
    "#### converting marketing forecast kycc to daily kycc cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5ffd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dates(month_year):\n",
    "\n",
    "    \n",
    "    date = pd.to_datetime(month_year, format='%b %y', errors='coerce')\n",
    "    \n",
    "    first_day = date\n",
    "    last_day = date + MonthEnd(1)\n",
    "    \n",
    "    return pd.date_range(start=first_day, end=last_day).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca01cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohort_df(sheet_id=parameters['sheet_id'],\n",
    "              raw_marketing_forecast=parameters['raw_marketing_forecast'],\n",
    "              tnc_to_lang=parameters['tnc_to_lang'],\n",
    "              intra_month=parameters['intra_month'],\n",
    "              intra_week=parameters['intra_week'],\n",
    "              cohorts=parameters['cohorts']):\n",
    "    \n",
    "    df = fc.import_gsheet_to_df(sheet_id, raw_marketing_forecast) #importing data from gsheet\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].replace(',','',regex=True).astype('int32') #converting integers\n",
    "    \n",
    "    df = df[df['KYCC']!='Total'] #removing total\n",
    "    \n",
    "    c_code = {'Germany':'DEU','Austria':'AUT','Spain':'ESP','France':'FRA','Italy':'ITA','Spain':'ESP','Greater Europe':'GrE',\n",
    "          'Non-Euro':'NEuro'}\n",
    "    \n",
    "    df['TnC Country'] = df['KYCC'].map(c_code) #creating KYCC columns\n",
    "    \n",
    "    df = df.melt(id_vars=['KYCC','TnC Country'],var_name='Month',value_name='Total')\n",
    "    \n",
    "    # import tnc \n",
    "    tnc = fc.import_gsheet_to_df(sheet_id, tnc_to_lang)\n",
    "    \n",
    "    tnc.iloc[:,1:] = tnc.iloc[:,1:].replace('%','',regex=True).astype('float')\n",
    "    \n",
    "    merged_df = pd.merge(df, tnc, on='TnC Country')\n",
    "    \n",
    "    for col in tnc.columns:\n",
    "        if col != 'TnC Country':\n",
    "            merged_df[col] = merged_df['Total'] * (merged_df[col] / 100)\n",
    "            \n",
    "    df_melt = pd.melt(merged_df, id_vars=['Month'], value_vars=['de','en','es','fr','it'], var_name='language',\n",
    "        value_name='value')\n",
    "    \n",
    "    df_melt = df_melt.groupby(['Month','language'])['value'].sum().reset_index()\n",
    "    \n",
    "    df_melt['date'] = df_melt['Month'].str.strip().apply(generate_dates)\n",
    "    \n",
    "    data = df_melt.explode('date').reset_index(drop=True)\n",
    "    \n",
    "    data = data.sort_values(by=['date','language'])\n",
    "    \n",
    "    data['dom'] = data['date'].dt.day\n",
    "    data['dow'] = data['date'].dt.weekday + 1\n",
    "    data.rename(columns={'language':'business_line_alias'},inplace=True)\n",
    "    \n",
    "    intra_m = fc.import_gsheet_to_df(sheet_id, intra_month)\n",
    "    intra_w = fc.import_gsheet_to_df(sheet_id, intra_week)\n",
    "    \n",
    "    intra_m['dom'] = intra_m['dom'].astype('int32')\n",
    "    intra_w['dow'] = intra_w['dow'].astype('int32')\n",
    "    \n",
    "    data = pd.merge(data, intra_m, how='left', on=['dom','business_line_alias'])\n",
    "    data = pd.merge(data, intra_w, how='left', on=['dow','business_line_alias'])\n",
    "    data.rename(columns={'seasonality':'intra_week_seasonality'},inplace=True)\n",
    "    data = data[['Month','date','business_line_alias','value','dom','dow','intra_month_seasonality','intra_week_seasonality']]\n",
    "    data['daily'] = data['value'] / data['date'].dt.to_period('M').dt.days_in_month\n",
    "    \n",
    "    \n",
    "    data[['daily','intra_month_seasonality','intra_week_seasonality']] = data[['daily','intra_month_seasonality','intra_week_seasonality']].astype('float')\n",
    "    data['daily_adj'] = (data['daily'] * (1+data['intra_month_seasonality'])) * (1+data['intra_week_seasonality'])\n",
    "    data['daily_adj_total'] = data.groupby(['Month','business_line_alias'])['daily_adj'].transform('sum')\n",
    "    data['final_daily'] = (1+(data['value'] - data['daily_adj_total']) / data['daily_adj_total']) * data['daily_adj']\n",
    "    data = data[['date','business_line_alias','final_daily']]\n",
    "    data.rename(columns={'business_line_alias':'language'},inplace=True)\n",
    "    \n",
    "    \n",
    "    cohorts_1 = fc.import_gsheet_to_df(sheet_id, cohorts)\n",
    "    df_cohorts = pd.merge(data, cohorts_1, how='left', on='language')\n",
    "    df_cohorts.rename(columns={'date':'cohort_start_date','final_daily':'cohort_size'},inplace=True)\n",
    "    df_cohorts = df_cohorts[['cohort_start_date','business_line_alias','cohort_size']]\n",
    "    \n",
    "    return df_cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06a7d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cohorts = cohort_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d1b95",
   "metadata": {},
   "source": [
    "### generating df_vol_distro, kycc contact rates by business_line_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c7541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_distro(sheet_id=parameters['sheet_id'],\n",
    "              kycc_volume=parameters['kycc_volume']):\n",
    "    \n",
    "    \n",
    "    kycc = fc.import_gsheet_to_df(sheet_id, kycc_volume)\n",
    "    kycc['business_line_alias'] = 'ops-cs-L1-' + kycc['contact_language'] + '-' + kycc['channel']\n",
    "    \n",
    "    df_vol_distro = kycc[['days_since_kycc','business_line_alias','cs_contact_rate']]\n",
    "    \n",
    "    df_vol_distro.rename(columns={'days_since_kycc':'date_offset','cs_contact_rate':'vol_distro'},inplace=True)\n",
    "    \n",
    "    return df_vol_distro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337bde5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_vol_distro = vol_distro()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4664abb",
   "metadata": {},
   "source": [
    "---\n",
    "###### Join each cohort with corresponding volume distribution to create forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3af5651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-31 00:00:00\n",
      "2026-02-04 00:00:00\n",
      "                                   forecast\n",
      "forecast_date business_line_alias          \n",
      "2024-07-28    ops-cs-L1-de-call    0.000000\n",
      "              ops-cs-L1-de-chat    0.000000\n",
      "              ops-cs-L1-de-email   0.000000\n",
      "              ops-cs-L1-en-call    0.000000\n",
      "              ops-cs-L1-en-chat    0.000000\n",
      "...                                     ...\n",
      "2026-02-04    ops-cs-L1-fr-chat    1.517387\n",
      "              ops-cs-L1-fr-email   1.487039\n",
      "              ops-cs-L1-it-call    0.114473\n",
      "              ops-cs-L1-it-chat    0.715454\n",
      "              ops-cs-L1-it-email   0.400655\n",
      "\n",
      "[8355 rows x 1 columns]\n",
      "CPU times: user 451 ms, sys: 16.9 ms, total: 468 ms\n",
      "Wall time: 465 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# merge cohorts with volume distribution & calculate forecast values\n",
    "grouping_column           = 'business_line_alias'\n",
    "df_fc = df_cohorts.merge(df_vol_distro, left_on=[grouping_column], right_on=[grouping_column], how='inner')\n",
    "df_fc['cohort_start_date'] = pd.to_datetime(df_fc['cohort_start_date'], format='%d/%m/%Y')\n",
    "df_fc['cohort_size'] = pd.to_numeric(df_fc['cohort_size'])\n",
    "df_fc['vol_distro'] = pd.to_numeric(df_fc['vol_distro'])\n",
    "df_fc['date_offset'] = pd.to_numeric(df_fc['date_offset'])\n",
    "print(max(df_fc['cohort_start_date']))\n",
    "\n",
    "df_fc['forecast_date'] = df_fc['cohort_start_date'] + pd.to_timedelta(df_fc['date_offset'], unit='D') #causes perf warning but idk a more efficient way to do this ü§∑‚Äç‚ôÇÔ∏è\n",
    "df_fc['forecast_base'] = df_fc['cohort_size'] * df_fc['vol_distro']\n",
    "\n",
    "print(max(df_fc['forecast_date']))\n",
    "\n",
    "df_fc_grouped = df_fc.groupby(['forecast_date', 'business_line_alias']).agg(\n",
    "    forecast = pd.NamedAgg(column='forecast_base', aggfunc=sum)\n",
    "    #cohort_count = pd.NamedAgg(column='cohort_size', aggfunc=len)\n",
    ")\n",
    "print(df_fc_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c890796",
   "metadata": {},
   "source": [
    "---\n",
    "###### Seasonally adjust the forecast with intra-week and intra-month seasonality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca57d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_month = dict(\n",
    "    \n",
    "    # month seasonality:\n",
    "    sheet_id                    = '1qPVSHGL6kxQ-JDStTVAET4fVWIv9aVBu_gHzziMVEuc',\n",
    "    tab                         = 'intra-month_seasonality!A1:D'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "949f77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_week = dict(\n",
    "    \n",
    "    # week seasonality:\n",
    "    sheet_id                    = '1qPVSHGL6kxQ-JDStTVAET4fVWIv9aVBu_gHzziMVEuc',\n",
    "    tab                         = 'intra-week_seasonality!A1:E'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecaa8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust seasonality function\n",
    "def adj_seasonality(df,parameters_month=parameters_month,parameters_week=parameters_week):\n",
    "    \n",
    "    # reset index\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # getting day of week and day of month\n",
    "    df['dow'] = df['forecast_date'].dt.weekday+1\n",
    "    df['dom']  = df['forecast_date'].dt.day\n",
    "    \n",
    "    # getting seasonality numbers\n",
    "    month = fc.import_gsheet_to_df(parameters_month['sheet_id'], parameters_month['tab'])\n",
    "    week = fc.import_gsheet_to_df(parameters_week['sheet_id'], parameters_week['tab'])\n",
    "    \n",
    "    # converting data types\n",
    "    month['dom'] = month['dom'].astype('int32')\n",
    "    month['intra_month_seasonality'] = month['intra_month_seasonality'].astype('float')\n",
    "    week['dow'] = week['dow'].astype('int32')\n",
    "    week['seasonality'] = week['seasonality'].astype('float')\n",
    "    \n",
    "    #merging with month\n",
    "    df = df.merge(month,how='left',on=['business_line_alias','dom'])\n",
    "    df = df.drop(columns=['avg_vol'])\n",
    "    \n",
    "    # merging with week\n",
    "    df = df.merge(week,how='left',on=['business_line_alias','dow'])\n",
    "    \n",
    "    # adjusting the forecast\n",
    "    df['adj_forecast'] = df['forecast']*(1+df['intra_month_seasonality'])*(1+df['seasonality'])\n",
    "    \n",
    "    # choosing columns\n",
    "    df = df[['forecast_date','business_line_alias','adj_forecast']]\n",
    "    \n",
    "    # renaming column\n",
    "    df = df.rename(columns={'adj_forecast':'forecast'})\n",
    "    \n",
    "    df['forecast'] = df['forecast'].fillna(0)\n",
    "    \n",
    "    df['forecast_date'] = pd.to_datetime(df['forecast_date'])\n",
    "    \n",
    "    df['forecast_date'] = df['forecast_date'].dt.date\n",
    "    \n",
    "    df['forecast_date'] = pd.to_datetime(df['forecast_date'])\n",
    "    \n",
    "    df_holidays = fc.import_gsheet_to_df(parameters['holiday_sheet_id'], parameters['holiday_range'])\n",
    "    df_holidays['holiday_date'] = pd.to_datetime(df_holidays['holiday_date'], format='%d/%m/%Y')\n",
    "    df_holidays['holiday_offset_%'] = df_holidays['holiday_offset_%'].str.rstrip('%').astype('float') / 100.0\n",
    "    \n",
    "    df = df.merge(df_holidays, how='left', left_on=['forecast_date', 'business_line_alias'], right_on=['holiday_date', 'business_line_alias'])\n",
    "    df['holiday_offset_%'] = df['holiday_offset_%'].fillna(0.0)\n",
    "    df['holiday_vol_offset'] = df['forecast'] * df['holiday_offset_%']\n",
    "    df['forecast'] = df['forecast'] + df['holiday_vol_offset']\n",
    "    \n",
    "    df = df[['forecast_date','business_line_alias','forecast']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a72bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function\n",
    "df_fc_grouped = adj_seasonality(df = df_fc_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b51e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export parameters:\n",
    "gsheet_export_params = dict(\n",
    "    \n",
    "    df                 = df_fc_grouped,\n",
    "    gsheet_id          = parameters['sheet_id'],\n",
    "    gsheet_tab_name    = 'kycc_cs_vol',\n",
    "    include_df_headers = True,\n",
    "    tab_colour         = (0.0, 0.0, 0.0) #RGB tab colour\n",
    ")\n",
    "\n",
    "#date column must be turned into strings because datetime type is not JSON serialisable\n",
    "df_fc_grouped['forecast_date'] = df_fc_grouped['forecast_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "fc.export_df_to_google_sheet(**gsheet_export_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
